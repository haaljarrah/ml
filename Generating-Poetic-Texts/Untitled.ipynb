{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e360aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 15:15:43.326558: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-22 15:15:43.327777: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 15:15:43.354069: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 15:15:43.354846: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 15:15:43.816198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca489e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c35109",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[300000:800000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac121fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20445a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31eb1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148b5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=np.bool_)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=np.bool_)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53d403e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "               input_shape=(SEQ_LENGTH,\n",
    "                            len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e8b78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 33s 50ms/step - loss: 2.1485\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 32s 49ms/step - loss: 1.7309\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 32s 49ms/step - loss: 1.5976\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 32s 49ms/step - loss: 1.5277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbf78508ca0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a57be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ff141a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c0ab12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dants, i\n",
      "shall bring emilia forth.\n",
      "\n",
      "paulina:\n",
      "and i am thou should he should stand the speak the changed in the brother,\n",
      "the brother the stand and with the some stay,\n",
      "the wife the stand the strengthing the stay the care the changed the death,\n",
      "the some the surpless the shame the changed\n",
      "the great the speak the change the sense\n",
      "the cheer of \n",
      "oud man that did usurp his back?\n",
      "forgive the chatite of york for my seave the chain?\n",
      "\n",
      "richard:\n",
      "what say my soul be strength stay the montes\n",
      "with the state the speak the should be surselled the brother,\n",
      "and be it a surple the brother that what i have many love,\n",
      "the lady should not still be the cheek of heaven stand him of york.\n",
      "\n",
      "leontes:\n",
      "h\n",
      "our behalf\n",
      "armies of pestilence; and therein be caped thou dost to make her.\n",
      "\n",
      "duke of york:\n",
      "while heaven of my vain of the prove stay,\n",
      "this that thou that head me soul my woman,\n",
      "while be suppers and mine earl all the streepless\n",
      "that be some all the sens the benith, and the sir,\n",
      "she should he\n",
      "should be everit of the senver the prove.\n",
      "\n",
      "firs\n",
      "ng him with self and vain conceit,\n",
      "as if thou showless magate the country's;\n",
      "and is my lord, and but the caterself and with the marreated\n",
      "of the many be sign the seemite!\n",
      "i am out of tire and the king of ment thee.\n",
      "\n",
      "abritter:\n",
      "my this give the cheit of the flased come them and what so,\n",
      "and near day that see it is warrow in death\n",
      "in the war\n",
      "hath sent a letter to his father's houses.\n",
      "\n",
      "richard:\n",
      "what make her in the callain follower storder'd be\n",
      "the tender of my his love, nor i'll have beses,\n",
      "that the king as one: what say i newless,\n",
      "boning with a seem turn shall state letter,\n",
      "i am sold the went by a rigin's traward,\n",
      "now, send, prosender speak no like it better me:\n",
      "thos man be \n",
      "\n",
      "let two more summers wither in their prince,\n",
      "and your grief with we shopsess of the tillst,\n",
      "be out the grave his slain that thou silsk of his prave\n",
      "grave that thou should the sign; i show the heavenes stay,\n",
      "that sun stwer these her your fearns back thee.\n",
      "you must destried presence me my strataths shall are tailst,\n",
      "the shopt of the name a\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb7bb322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830ad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
